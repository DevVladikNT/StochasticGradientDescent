# StochasticGradientDescent

*В какой-то момент я переведу текст ниже на английский язык и он будет в этом месте.*

## О проекте

В [этом репозитории](https://github.com/DevVladikNT/GradientDescent) я уже рассматривал метод градиентного спуска и подробно описывал как именно он работает. Если у Вас возникают вопросы с пониманием самой сути градиента, лучше сначала зайти туда.

В данном проекте я бы хотел рассмотреть метод стохастического градиентного спуска, который чаще применяется на практике при большом объеме данных. Надеюсь, я смогу найти зависимость между размером выборки (batch size) и скоростью обучения,
после чего, попытаюсь ответить на вопрос: *Так ли важен размер выборки?*

## Как работает

В этом блоке я вкратце опишу суть метода.

### Какой-то пункт

Какой-то текст

## Программная реализация

Здесь будет описание файлов проекта

## Контакты

Вы можете найти меня здесь:
* [Telegram](https://t.me/VladikNT)
* [VK](https://vk.com/vladikvasilyev)

Также можете ознакомиться с моим [резюме](https://spb.hh.ru/resume/99523b52ff0b01b5930039ed1f61316f397567).
